version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: lululemon-postgres
    environment:
      POSTGRES_DB: scraper
      POSTGRES_USER: scraper_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-supersecretpassword123}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scraper_user -d scraper"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scraper-network

  # Lululemon Scraper Application
  scraper:
    build: .
    container_name: lululemon-scraper
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "5000:5000"
    volumes:
      # Persist scraped data and Excel files
      - scraper_data:/app/backend/data
      # Persist logs
      - scraper_logs:/app/backend/logs
    environment:
      - FLASK_ENV=production
      - SECRET_KEY=${SECRET_KEY:-change-this-secret-key-in-production}
      - DATABASE_URL=postgresql://scraper_user:${POSTGRES_PASSWORD:-supersecretpassword123}@postgres:5432/scraper
      - RESEND_API_KEY=${RESEND_API_KEY:-}
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - scraper-network

networks:
  scraper-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  scraper_data:
    driver: local
  scraper_logs:
    driver: local
